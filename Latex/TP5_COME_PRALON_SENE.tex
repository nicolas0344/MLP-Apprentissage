\documentclass[a4paper,french,10pt]{article}
\usepackage{homework}

% change le nom de la table des matières
\addto\captionsfrench{\renewcommand*\contentsname{Sommaire}}

\lstdefinelanguage{Python}%
{morekeywords={function,for,in,if,elseif,else,TRUE,FALSE,%
		return, while, sum, sqrt, plot, mean, boxplot, data, model,matrix, print, from, import, as, hidden_layer_sizes, activation, solver,
		fit, model_svm, parameters2, n_jobs, cv, n_splits, n_repeats},%
	sensitive=true,%
	morecomment=[l]{\#},%
	morestring=[s]{"}{"},%
	morestring=[s]{'}{'},%
}[keywords,comments,strings]%

\lstset{%
	language         = Python,
	basicstyle       = \ttfamily,
	keywordstyle     = \bfseries\color{blue},
	stringstyle      = \color{orange},
	commentstyle     = \color{magenta},
	showstringspaces = false,
	literate={á}{{\'a}}1 {ã}{{\~a}}1 {é}{{\'e}}1,
}

\begin{document}
	
	% Blank out the traditional title page
	\title{\vspace{-1in}} % no title name
	\author{} % no author name
	\date{} % no date listed
	\maketitle % makes this a title page
	
	% Use custom title macro instead
	\usebox{\myReportTitle}
	\vspace{1in} % spacing below title header
	
	% Assignment title
	{\centering \huge \assignmentName \par}
	{\centering \noindent\rule{4in}{0.1pt} \par}
	\vspace{0.05in}
	{\centering \courseCode~: \courseName~ \par}
	{\centering Rédigé le \pubDate\ en \LaTeX \par}
	\vspace{1in}
	
	% Table of Contents
	\tableofcontents
	\newpage
	
	%----------------------------------------------------------------------------------------
	%	EXERCICE 1
	%----------------------------------------------------------------------------------------
	
	\section{Question 1}
	
	\underline{Présentons très synthétiquement le jeu de données pour le \textit{AND}, \textit{XOR} et \textit{OR}:}
	
	\begin{figure}[htp] 
		\centering
		\subfloat[Graphique du jeu de données \textit{AND}]{%
			\includegraphics[scale=1.0]{images/AND.png}%
		}%
		\hfill%
		\subfloat[Graphique du jeu de données \textit{XOR}]{%
			\includegraphics[scale=1.0]{images/XOR.png}%
		}%
		\hfill%
		\subfloat[Graphique du jeu de données \textit{OR}]{%
			\includegraphics[scale=1.0]{images/OR.png}%
		}%
	\end{figure}
	Les difficultés de classification résident dans le fait que les données du \textit{XOR} ne sont pas linéairement séparables. Sur le graphique (b) on voit qu'il y a deux droites de séparation et non une seule. De ce fait, un seul neurone ne peut réussir à classifier les données.
	
	\section{Question 2}
	
	\underline{Définissons un classifieur \textit{MLP} pour apprendre l’opérateur \textit{AND}:}
	
	\lstinputlisting[language=Python, firstline=68, 
	lastline=69]{code/MLP.py}
	
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.7]{images/Q2.png}
		\caption{Score obtenu par le classifieur $MLP$ sur les données de test de l'opérateur $AND$}
	\end{figure}
	Dans le cas où l'on souhaite apprendre l'opérateur $AND$, le classifieur $MLP$ ne comprenant aucune couche cachée fournit de très bons résultats en terme de prédiction. Comme on peut le voir sur la figure 1, le classifieur ne fait aucune erreur de prédiction (le score vaut $1$). Pour calculer ce score nous avons utiliser la fonction $score(x\_test, y\_test)$ de $sklearn$.
	\section{Question 3}
	
	\underline{Définissons un classifieur \textit{MLP} pour apprendre l’opérateur \textit{OR}:}
	
	\lstinputlisting[language=Python, firstline=78, 
	lastline=79]{code/MLP.py}
	
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.7]{images/Q3.png}
		\caption{Score obtenu par le classifieur $MLP$ sur les données de test de l'opérateur $OR$}
	\end{figure}
	Dans le cas où l'on souhaite apprendre l'opérateur $OR$, le classifieur $MLP$ ne comprenant aucune couche cachée fournit de très bons résultats en terme de prédiction. Comme on peut le voir sur la figure 2, le classifieur ne fait aucune erreur de prédiction (le score vaut $1$). Pour calculer ce score nous avons utiliser la fonction $score(x\_test, y\_test)$ de $sklearn$.
	
	\section{Question 4}

	\subsection{Question 4a)}
	
	\underline{Définissons un classifieur \textit{MLP} sans couche cachée pour apprendre l’opérateur \textit{XOR}:}
	
	\lstinputlisting[language=Python, firstline=88, 
	lastline=89]{code/MLP.py}
	
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.7]{images/Q4a.png}
		\caption{Score obtenu par le classifieur $MLP$ sur les données de test de l'opérateur $XOR$ sans utiliser de couches cachées}
	\end{figure}
	Dans le cas où l'on souhaite apprendre l'opérateur $XOR$, le classifieur $MLP$ ne comprenant aucune couche cachée fournit de mauvais résultats en terme de prédiction. Comme on peut le voir sur la figure 3, la précision de prédiction du classifieur est de $50\%$ (le score vaut $0.5$), ce qui est assez bas.\\
	Cela s'explique par le fait qu'un perceptron ne peut apprendre que sur des données linéairement séparables or ce n'est ici pas le cas.
	
	\subsection{Question 4b)}
	
	\underline{Définissons un classifieur \textit{MLP} avec deux couches cachées pour apprendre l’opérateur \textit{XOR}:}
	
	\lstinputlisting[language=Python, firstline=94, 
	lastline=95]{code/MLP.py}
	
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.7]{images/Q4b.png}
		\caption{Score obtenu par le classifieur $MLP$ sur les données de test de l'opérateur $XOR$ en utilisant $2$ couches cachées}
	\end{figure}
	Le classifieur $MLP$ comprenant deux couches cachées ($4$ neurones sur la première couche et $2$ neurones sur la deuxième) fournit de meilleurs résultats (en terme de prédiction) que le classifieur ne comprenant aucune couche cachée. En effet, comme on peut le voir sur la figure 4, la précision de prédiction de ce nouveau classifieur est de $75\%$ contre $50\%$ pour le précédent.\\
	Cela s'explique par le fait que l'ajout de couches cachées dans un perceptron permet de transformer un problème non linéairement séparable en un problème linéairement séparable. Ce nouveau classifieur (perceptron multi-couche) sera donc en mesure d'apprendre l'opérateur XOR contrairement au précèdent.
	
	\pagebreak
	
	\subsection{Question 4c)}
	
	\underline{Classifieur \textit{MLP} avec deux couches cachées et des fonctions d'activation $tanh$ pour apprendre l’opérateur \textit{XOR}:}
	
	\lstinputlisting[language=Python, firstline=100, 
	lastline=101]{code/MLP.py}
	
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.7]{images/Q4c.png}
		\caption{Score obtenu par le classifieur $MLP$ sur les données de test de l'opérateur $XOR$ en utilisant $2$ couches cachées et des fonctions d'activation $tanh$}
	\end{figure}
	Les résultats obtenus ici sont encore mieux que ceux obtenus dans les deux cas précédents. En effet, comme on peut le voir sur la figure 5, la précision de prédiction de ce nouveau classifieur est de $100\%$ contre $75\%$ et $50\%$ pour les deux précédents.
	Les fonctions d'activation hyperbolique ($tanh$) cherchent des séparateurs non linéaires or nos données sont ici non linéairement séparables. Par conséquent, ces fonctions d'activation seront bien adaptées à notre situation. Cela explique pourquoi les résultats obtenus ici sont mieux que ceux obtenus précédemment.
	
	\section{Question 5}
	
	Notre jeu de données est composé d'images (de taille 8$\times$8 c'est à dire $64$ pixels) de chiffre manuscrit. On veut identifier le chiffre contenu dans une image. On cherche donc ici à mettre en place un réseau de neurones qui sera capable de classifier ces images. Étant donné qu'il y a $10$ chiffres allant de $0$ à $9$, nous aurons ici un nombre total de $10$ classes.\\\\
	
	Nous allons comparer les performances de plusieurs classifieurs que nous aurons créés en jouant sur différents paramètres de $MLPclassifieur$. Nous regrouperons ces performances dans un tableau puis nous regarderons quel classifieur fournit les meilleurs performances.
	
	\begin{figure}[htp] 
		\centering
		\subfloat[Dataframe des scores des différents classifieurs utilisés]{%
			\includegraphics[scale=0.65]{images/df_MLP.png}%
		}%
		\hfill%
		\subfloat[Meilleurs $MLP$ en fonctions des différentes fonctions d'activations]{%
			\includegraphics[scale=1.4]{images/best_MLP.png}%
		}%
		\caption{}
	\end{figure}
	
	D'après la figure $6$, on constate que les classifieurs sans couche cachée sont les plus performants. Ce résultat est étonnant puisqu'ici, les données sont linéairement non séparables. Les classifieurs $MLP$ ayant les meilleurs performances sont ceux ayant pour fonctions d'activation la fonction tangente hyperbolique ($tanh$) et la fonction linéaire ($identity$). Étant donné que les données sont linéairement non séparables, on se serait plutôt attendu à avoir de meilleurs résultats avec la fonction d'activation $tanh$ et l'optimiseur $adam$.
	
	
	\section{Question 6}
	
	Dans cette dernière question nous comparons le classifieur $MLP$ obtenu dans la question précédente avec deux classifieurs $SVM$. Afin de déterminer le meilleur de ces trois classifieurs, nous évaluons les performances des deux classifieurs $SVM$ en validation croisée avec un \textit{k-fold} ($k = 5$).
	
	\lstinputlisting[language=Python, firstline=181, 
	lastline=196]{code/MLP.py}
	
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.7]{images/SVM_vs_MLP.png}
		\caption{Comparaison entre le classifieur $SVM$ et $MLP$}
	\end{figure}
	
	D'après la figure $7$, on constate que le classifieur $SVM$ avec le noyau polynomial est le meilleur car c'est celui ayant le score le plus élevé.
	
	\section{Lien git du TP}
	Vous pourrez accéder au code python complet (fichier intitulé $MLP.py$) que nous avons implémenté afin de répondre aux questions de ce TP via le lien git suivant:\\
	\url{https://github.com/nicolas0344/MLP-Apprentissage.git}
	
\end{document}
